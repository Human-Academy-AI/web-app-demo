from flask import Flask, render_template, request, jsonify
import boto3
import cv2
import numpy as np
import base64
import io
import os
from PIL import Image, ImageDraw, ImageFont

app = Flask(__name__)

if 'AWS_SHARED_CREDENTIALS_FILE' not in os.environ:
  os.environ['AWS_SHARED_CREDENTIALS_FILE'] = '/content/.aws/credentials'
if 'AWS_CONFIG_FILE' not in os.environ:
  os.environ['AWS_CONFIG_FILE'] = '/content/.aws/config'

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š ---
REGION_NAME = "ap-northeast-1"
# -------------------------------------------

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/analyze', methods=['POST'])
def analyze():
    try:
        data = request.json
        img_data_b64 = data['image'].split(',')[1]

        img_bytes = base64.b64decode(img_data_b64)
        image = Image.open(io.BytesIO(img_bytes))
        img_w, img_h = image.size

        # --- ã“ã“ãŒä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼šå…¨ã¦ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«éµã‚’æ¸¡ã™ ---
        rekognition = boto3.client('rekognition',region_name=REGION_NAME)
        polly = boto3.client('polly',region_name=REGION_NAME)
        translate = boto3.client('translate',region_name=REGION_NAME)

        # ----------------------------------------------------

        # èªè­˜å®Ÿè¡Œ
        response = rekognition.detect_labels(
            Image={'Bytes': img_bytes}, MaxLabels=20, MinConfidence=50
        )
        labels = response['Labels']

        # --- è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆç”¨ ---
        debug_lines = ["ğŸ“¸ è§£æå®Œäº†", "--- ãƒˆãƒƒãƒ—5 (æ—¥æœ¬èªå¤‰æ›) ---"]

        draw = ImageDraw.Draw(image)
        try:
            font = ImageFont.truetype("static/font.ttf", 30)
        except:
            font = ImageFont.load_default()

        speech_text = ""
        found_main_object = False

        for i, label in enumerate(labels[:5]):
            en_name = label['Name']

            # ç¿»è¨³å®Ÿè¡Œ
            trans_res = translate.translate_text(
                Text=en_name, SourceLanguageCode='en', TargetLanguageCode='ja'
            )
            ja_name = trans_res['TranslatedText']

            instances = label.get('Instances', [])
            status = "æ ãªã—"

            if len(instances) > 0:
                status = "âœ… æ ã‚ã‚Š"
                if not found_main_object:
                    speech_text = f"{ja_name}ã‚’è¦‹ã¤ã‘ã¾ã—ãŸ"
                    found_main_object = True

                for instance in instances:
                    box = instance['BoundingBox']
                    x1 = box['Left'] * img_w
                    y1 = box['Top'] * img_h
                    x2 = (box['Left'] + box['Width']) * img_w
                    y2 = (box['Top'] + box['Height']) * img_h

                    # ç·‘ã®æ 
                    draw.rectangle([x1, y1, x2, y2], outline=(0, 255, 0), width=5)

                    # ãƒ†ã‚­ã‚¹ãƒˆæç”»
                    text_w = draw.textlength(ja_name, font=font)
                    text_bg = [x1, y1 - 35, x1 + text_w + 10, y1]
                    draw.rectangle(text_bg, fill=(0, 255, 0))
                    draw.text((x1 + 5, y1 - 35), ja_name, font=font, fill=(255, 255, 255))

            debug_lines.append(f"{i+1}. {en_name} -> ã€Œ{ja_name}ã€ ({status})")

        result_text = "\n".join(debug_lines)

        if not speech_text:
            if labels:
                top_en = labels[0]['Name']
                top_trans = translate.translate_text(Text=top_en, SourceLanguageCode='en', TargetLanguageCode='ja')
                top_ja = top_trans['TranslatedText']
                speech_text = f"ãŸã¶ã‚“ã€{top_ja}ã ã¨æ€ã„ã¾ã™"
            else:
                speech_text = "ä½•ã‚‚ã‚ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"

        # éŸ³å£°åˆæˆ
        polly_res = polly.synthesize_speech(
            Text=speech_text, OutputFormat='mp3', VoiceId='Kazuha', Engine='neural'
        )
        audio_stream = polly_res['AudioStream'].read()
        audio_b64 = base64.b64encode(audio_stream).decode()

        buf = io.BytesIO()
        image.save(buf, format='JPEG')
        processed_img_b64 = "data:image/jpeg;base64," + base64.b64encode(buf.getvalue()).decode()

        return jsonify({
            'image': processed_img_b64,
            'text': result_text,
            'audio': audio_b64
        })

    except Exception as e:
        return jsonify({'error': str(e)})

if __name__ == '__main__':
    app.run(port=5000)
